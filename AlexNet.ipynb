{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jdu12\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "#import pickle, datetime\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import  PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jdu12/Desktop/research/saved_models/AlexNet/\n"
     ]
    }
   ],
   "source": [
    "root_path = '/Users/jdu12/Desktop/research/'\n",
    "model_dir = root_path + 'saved_models/AlexNet/'\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5075 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "N_CATEGORY = 36\n",
    "BATCH_SIZE = 128\n",
    "train_data_dir = '/Users/jdu12/Desktop/research/input'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(227, 227),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "#print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, N_CATEGORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.5\n",
    "model_input = Input(shape = (227, 227, 3))\n",
    "\n",
    "# First convolutional Layer (96x11x11)\n",
    "z = Conv2D(filters = 96, kernel_size = (11,11), strides = (4,4), activation = \"relu\")(model_input)\n",
    "z = MaxPooling2D(pool_size = (3,3), strides=(2,2))(z)\n",
    "z = BatchNormalization()(z)\n",
    "\n",
    "# Second convolutional Layer (256x5x5)\n",
    "z = ZeroPadding2D(padding = (2,2))(z)\n",
    "z = Convolution2D(filters = 256, kernel_size = (5,5), strides = (1,1), activation = \"relu\")(z)\n",
    "z = MaxPooling2D(pool_size = (3,3), strides=(2,2))(z)\n",
    "z = BatchNormalization()(z)\n",
    "\n",
    "# Rest 3 convolutional layers\n",
    "z = ZeroPadding2D(padding = (1,1))(z)\n",
    "z = Convolution2D(filters = 384, kernel_size = (3,3), strides = (1,1), activation = \"relu\")(z)\n",
    "\n",
    "z = ZeroPadding2D(padding = (1,1))(z)\n",
    "z = Convolution2D(filters = 384, kernel_size = (3,3), strides = (1,1), activation = \"relu\")(z)\n",
    "\n",
    "z = ZeroPadding2D(padding = (1,1))(z)\n",
    "z = Convolution2D(filters = 256, kernel_size = (3,3), strides = (1,1), activation = \"relu\")(z)\n",
    "\n",
    "z = MaxPooling2D(pool_size = (3,3), strides=(2,2))(z)\n",
    "z = Flatten()(z)\n",
    "\n",
    "z = Dense(4096, activation=\"relu\")(z)\n",
    "z = Dropout(DROPOUT)(z)\n",
    "\n",
    "z = Dense(4096, activation=\"relu\")(z)\n",
    "z = Dropout(DROPOUT)(z)\n",
    "\n",
    "final_dim = 1 if N_CATEGORY == 2 else N_CATEGORY\n",
    "final_act = \"sigmoid\" if N_CATEGORY == 2 else \"softmax\"\n",
    "model_output = Dense(final_dim, activation=final_act)(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport time\\nimport pylab as pl\\nfrom IPython import display\\npl.style.use(\\'ggplot\\')\\n%matplotlib inline\\n\\nclass Histories(keras.callbacks.Callback):\\n\\n    def on_train_begin(self, logs={}):\\n        self.acc = []\\n        self.loss = []\\n        self.val_loss = []\\n        self.val_acc = []\\n\\n    def on_train_end(self, logs={}):\\n        return\\n\\n    def on_epoch_begin(self, epoch, logs={}):\\n        return\\n\\n    def on_epoch_end(self, epoch, logs={}):\\n        self.acc.append(logs[\\'acc\\'])\\n        self.loss.append(logs[\\'loss\\'])\\n        self.val_acc.append(logs[\\'val_acc\\'])\\n        self.val_loss.append(logs[\\'val_loss\\'])\\n        \\n        pl.hold(True)\\n        plt.rcParams[\"figure.figsize\"] = (8,5)\\n        pl.plot(self.acc, \\'r\\')\\n        pl.plot(self.loss, \\'b\\')\\n        pl.plot(self.val_acc, \\'g\\')\\n        pl.plot(self.val_loss, \\'k\\')\\n        pl.legend([\\'Train acc\\',\\'Train loss\\',\\'Valid acc\\', \\'Valid loss\\'], loc=2)\\n        display.clear_output(wait=True)\\n        display.display(pl.gcf())\\n        return\\n\\n    def on_batch_begin(self, batch, logs={}):\\n        return\\n\\n    def on_batch_end(self, batch, logs={}):\\n        return\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "pl.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "class Histories(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.acc.append(logs['acc'])\n",
    "        self.loss.append(logs['loss'])\n",
    "        self.val_acc.append(logs['val_acc'])\n",
    "        self.val_loss.append(logs['val_loss'])\n",
    "        \n",
    "        pl.hold(True)\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "        pl.plot(self.acc, 'r')\n",
    "        pl.plot(self.loss, 'b')\n",
    "        pl.plot(self.val_acc, 'g')\n",
    "        pl.plot(self.val_loss, 'k')\n",
    "        pl.legend(['Train acc','Train loss','Valid acc', 'Valid loss'], loc=2)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/190\n",
      " - 11s - loss: 3.0004 - acc: 0.1573\n",
      "Epoch 2/190\n",
      " - 10s - loss: 1.1771 - acc: 0.5520\n",
      "Epoch 3/190\n",
      " - 11s - loss: 0.6384 - acc: 0.7593\n",
      "Epoch 4/190\n",
      " - 10s - loss: 0.4108 - acc: 0.8625\n",
      "Epoch 5/190\n",
      " - 11s - loss: 0.3637 - acc: 0.8832\n",
      "Epoch 6/190\n",
      " - 11s - loss: 0.3606 - acc: 0.8861\n",
      "Epoch 7/190\n",
      " - 11s - loss: 0.2085 - acc: 0.9452\n",
      "Epoch 8/190\n",
      " - 11s - loss: 0.2255 - acc: 0.9311\n",
      "Epoch 9/190\n",
      " - 11s - loss: 0.1732 - acc: 0.9516\n",
      "Epoch 10/190\n",
      " - 10s - loss: 0.1486 - acc: 0.9626\n",
      "Epoch 11/190\n",
      " - 11s - loss: 0.1603 - acc: 0.9562\n",
      "Epoch 12/190\n",
      " - 11s - loss: 0.1552 - acc: 0.9581\n",
      "Epoch 13/190\n",
      " - 11s - loss: 0.1469 - acc: 0.9571\n",
      "Epoch 14/190\n",
      " - 11s - loss: 0.1618 - acc: 0.9539\n",
      "Epoch 15/190\n",
      " - 11s - loss: 0.1400 - acc: 0.9573\n",
      "Epoch 16/190\n",
      " - 10s - loss: 0.1175 - acc: 0.9669\n",
      "Epoch 17/190\n",
      " - 9s - loss: 0.0898 - acc: 0.9768\n",
      "Epoch 18/190\n",
      " - 9s - loss: 0.0814 - acc: 0.9774\n",
      "Epoch 19/190\n",
      " - 9s - loss: 0.0913 - acc: 0.9730\n",
      "Epoch 20/190\n",
      " - 9s - loss: 0.0903 - acc: 0.9717\n",
      "Epoch 21/190\n",
      " - 9s - loss: 0.0887 - acc: 0.9722\n",
      "Epoch 22/190\n",
      " - 8s - loss: 0.0831 - acc: 0.9763\n",
      "Epoch 23/190\n",
      " - 9s - loss: 0.0558 - acc: 0.9850\n",
      "Epoch 24/190\n",
      " - 9s - loss: 0.0892 - acc: 0.9732\n",
      "Epoch 25/190\n",
      " - 9s - loss: 0.0598 - acc: 0.9805\n",
      "Epoch 26/190\n",
      " - 9s - loss: 0.0572 - acc: 0.9831\n",
      "Epoch 27/190\n",
      " - 9s - loss: 0.0696 - acc: 0.9782\n",
      "Epoch 28/190\n",
      " - 8s - loss: 0.0785 - acc: 0.9749\n",
      "Epoch 29/190\n",
      " - 9s - loss: 0.0563 - acc: 0.9842\n",
      "Epoch 30/190\n",
      " - 9s - loss: 0.0307 - acc: 0.9914\n",
      "Epoch 31/190\n",
      " - 9s - loss: 0.0311 - acc: 0.9903\n",
      "Epoch 32/190\n",
      " - 9s - loss: 0.0299 - acc: 0.9903\n",
      "Epoch 33/190\n",
      " - 9s - loss: 0.0310 - acc: 0.9911\n",
      "Epoch 34/190\n",
      " - 8s - loss: 0.0291 - acc: 0.9896\n",
      "Epoch 35/190\n",
      " - 9s - loss: 0.0282 - acc: 0.9898\n",
      "Epoch 36/190\n",
      " - 9s - loss: 0.0344 - acc: 0.9883\n",
      "Epoch 37/190\n",
      " - 8s - loss: 0.0689 - acc: 0.9773\n",
      "Epoch 38/190\n",
      " - 9s - loss: 0.0881 - acc: 0.9717\n",
      "Epoch 39/190\n",
      " - 9s - loss: 0.0298 - acc: 0.9896\n",
      "Epoch 40/190\n",
      " - 8s - loss: 0.0615 - acc: 0.9802\n",
      "Epoch 41/190\n",
      " - 9s - loss: 0.0368 - acc: 0.9879\n",
      "Epoch 42/190\n",
      " - 9s - loss: 0.0252 - acc: 0.9914\n",
      "Epoch 43/190\n",
      " - 9s - loss: 0.0093 - acc: 0.9962\n",
      "Epoch 44/190\n",
      " - 9s - loss: 0.0102 - acc: 0.9957\n",
      "Epoch 45/190\n",
      " - 9s - loss: 0.0290 - acc: 0.9903\n",
      "Epoch 46/190\n",
      " - 8s - loss: 0.0512 - acc: 0.9840\n",
      "Epoch 47/190\n",
      " - 9s - loss: 0.0373 - acc: 0.9880\n",
      "Epoch 48/190\n",
      " - 9s - loss: 0.0129 - acc: 0.9953\n",
      "Epoch 49/190\n",
      " - 8s - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 50/190\n",
      " - 9s - loss: 0.0276 - acc: 0.9916\n",
      "Epoch 51/190\n",
      " - 9s - loss: 0.0088 - acc: 0.9971\n",
      "Epoch 52/190\n",
      " - 8s - loss: 0.0100 - acc: 0.9957\n",
      "Epoch 53/190\n",
      " - 9s - loss: 0.0192 - acc: 0.9943\n",
      "Epoch 54/190\n",
      " - 9s - loss: 0.0762 - acc: 0.9776\n",
      "Epoch 55/190\n",
      " - 8s - loss: 0.0503 - acc: 0.9824\n",
      "Epoch 56/190\n",
      " - 9s - loss: 0.0299 - acc: 0.9893\n",
      "Epoch 57/190\n",
      " - 9s - loss: 0.0330 - acc: 0.9904\n",
      "Epoch 58/190\n",
      " - 8s - loss: 0.0614 - acc: 0.9829\n",
      "Epoch 59/190\n",
      " - 9s - loss: 0.0368 - acc: 0.9877\n",
      "Epoch 60/190\n",
      " - 9s - loss: 0.0211 - acc: 0.9929\n",
      "Epoch 61/190\n",
      " - 8s - loss: 0.0200 - acc: 0.9927\n",
      "Epoch 62/190\n",
      " - 9s - loss: 0.0209 - acc: 0.9924\n",
      "Epoch 63/190\n",
      " - 9s - loss: 0.0113 - acc: 0.9955\n",
      "Epoch 64/190\n",
      " - 8s - loss: 0.0129 - acc: 0.9961\n",
      "Epoch 65/190\n",
      " - 9s - loss: 0.0291 - acc: 0.9892\n",
      "Epoch 66/190\n",
      " - 9s - loss: 0.0347 - acc: 0.9877\n",
      "Epoch 67/190\n",
      " - 8s - loss: 0.0276 - acc: 0.9907\n",
      "Epoch 68/190\n",
      " - 9s - loss: 0.0084 - acc: 0.9979\n",
      "Epoch 69/190\n",
      " - 9s - loss: 0.0062 - acc: 0.9977\n",
      "Epoch 70/190\n",
      " - 8s - loss: 0.0086 - acc: 0.9967\n",
      "Epoch 71/190\n",
      " - 9s - loss: 0.0109 - acc: 0.9977\n",
      "Epoch 72/190\n",
      " - 9s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 73/190\n",
      " - 8s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 74/190\n",
      " - 9s - loss: 0.0037 - acc: 0.9980\n",
      "Epoch 75/190\n",
      " - 9s - loss: 0.0059 - acc: 0.9977\n",
      "Epoch 76/190\n",
      " - 8s - loss: 0.0059 - acc: 0.9979\n",
      "Epoch 77/190\n",
      " - 9s - loss: 0.0096 - acc: 0.9963\n",
      "Epoch 78/190\n",
      " - 9s - loss: 0.0204 - acc: 0.9941\n",
      "Epoch 79/190\n",
      " - 8s - loss: 0.0158 - acc: 0.9949\n",
      "Epoch 80/190\n",
      " - 9s - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 81/190\n",
      " - 9s - loss: 0.0244 - acc: 0.9916\n",
      "Epoch 82/190\n",
      " - 8s - loss: 0.0466 - acc: 0.9869\n",
      "Epoch 83/190\n",
      " - 9s - loss: 0.0369 - acc: 0.9889\n",
      "Epoch 84/190\n",
      " - 9s - loss: 0.0099 - acc: 0.9964\n",
      "Epoch 85/190\n",
      " - 8s - loss: 0.0160 - acc: 0.9961\n",
      "Epoch 86/190\n",
      " - 8s - loss: 0.0125 - acc: 0.9965\n",
      "Epoch 87/190\n",
      " - 9s - loss: 0.0111 - acc: 0.9959\n",
      "Epoch 88/190\n",
      " - 8s - loss: 0.0078 - acc: 0.9969\n",
      "Epoch 89/190\n",
      " - 9s - loss: 0.0045 - acc: 0.9984\n",
      "Epoch 90/190\n",
      " - 9s - loss: 0.0148 - acc: 0.9955\n",
      "Epoch 91/190\n",
      " - 8s - loss: 0.0113 - acc: 0.9965\n",
      "Epoch 92/190\n",
      " - 9s - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 93/190\n",
      " - 9s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 94/190\n",
      " - 8s - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 95/190\n",
      " - 9s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 96/190\n",
      " - 9s - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 97/190\n",
      " - 8s - loss: 0.0115 - acc: 0.9967\n",
      "Epoch 98/190\n",
      " - 9s - loss: 0.0179 - acc: 0.9959\n",
      "Epoch 99/190\n",
      " - 9s - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 100/190\n",
      " - 8s - loss: 0.0072 - acc: 0.9979\n",
      "Epoch 101/190\n",
      " - 9s - loss: 0.0072 - acc: 0.9973\n",
      "Epoch 102/190\n",
      " - 9s - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 103/190\n",
      " - 8s - loss: 0.0165 - acc: 0.9951\n",
      "Epoch 104/190\n",
      " - 9s - loss: 0.0217 - acc: 0.9934\n",
      "Epoch 105/190\n",
      " - 9s - loss: 0.0143 - acc: 0.9941\n",
      "Epoch 106/190\n",
      " - 8s - loss: 0.0180 - acc: 0.9946\n",
      "Epoch 107/190\n",
      " - 8s - loss: 0.0246 - acc: 0.9926\n",
      "Epoch 108/190\n",
      " - 9s - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 109/190\n",
      " - 8s - loss: 0.0213 - acc: 0.9943\n",
      "Epoch 110/190\n",
      " - 9s - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 111/190\n",
      " - 9s - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 112/190\n",
      " - 8s - loss: 0.0245 - acc: 0.9928\n",
      "Epoch 113/190\n",
      " - 9s - loss: 0.0258 - acc: 0.9930\n",
      "Epoch 114/190\n",
      " - 9s - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 115/190\n",
      " - 8s - loss: 0.0078 - acc: 0.9979\n",
      "Epoch 116/190\n",
      " - 9s - loss: 0.0062 - acc: 0.9980\n",
      "Epoch 117/190\n",
      " - 9s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 118/190\n",
      " - 8s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 119/190\n",
      " - 9s - loss: 6.5952e-04 - acc: 0.9998\n",
      "Epoch 120/190\n",
      " - 9s - loss: 3.5544e-04 - acc: 1.0000\n",
      "Epoch 121/190\n",
      " - 8s - loss: 2.0257e-04 - acc: 1.0000\n",
      "Epoch 122/190\n",
      " - 9s - loss: 3.0306e-04 - acc: 1.0000\n",
      "Epoch 123/190\n",
      " - 9s - loss: 3.5964e-04 - acc: 1.0000\n",
      "Epoch 124/190\n",
      " - 8s - loss: 0.0014 - acc: 0.9994\n",
      "Epoch 125/190\n",
      " - 9s - loss: 8.4362e-04 - acc: 1.0000\n",
      "Epoch 126/190\n",
      " - 9s - loss: 3.6755e-04 - acc: 1.0000\n",
      "Epoch 127/190\n",
      " - 8s - loss: 2.7125e-04 - acc: 1.0000\n",
      "Epoch 128/190\n",
      " - 9s - loss: 1.4237e-04 - acc: 1.0000\n",
      "Epoch 129/190\n",
      " - 9s - loss: 1.1236e-04 - acc: 1.0000\n",
      "Epoch 130/190\n",
      " - 8s - loss: 3.5048e-04 - acc: 0.9998\n",
      "Epoch 131/190\n",
      " - 8s - loss: 0.0033 - acc: 0.9994\n",
      "Epoch 132/190\n",
      " - 9s - loss: 0.0020 - acc: 0.9989\n",
      "Epoch 133/190\n",
      " - 8s - loss: 0.0016 - acc: 0.9992\n",
      "Epoch 134/190\n",
      " - 9s - loss: 0.0010 - acc: 0.9996\n",
      "Epoch 135/190\n",
      " - 9s - loss: 2.6107e-04 - acc: 1.0000\n",
      "Epoch 136/190\n",
      " - 8s - loss: 6.2188e-04 - acc: 0.9998\n",
      "Epoch 137/190\n",
      " - 8s - loss: 0.0309 - acc: 0.9932\n",
      "Epoch 138/190\n",
      " - 9s - loss: 0.0275 - acc: 0.9912\n",
      "Epoch 139/190\n",
      " - 8s - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 140/190\n",
      " - 9s - loss: 0.0179 - acc: 0.9932\n",
      "Epoch 141/190\n",
      " - 9s - loss: 0.0162 - acc: 0.9957\n",
      "Epoch 142/190\n",
      " - 8s - loss: 0.0072 - acc: 0.9971\n",
      "Epoch 143/190\n",
      " - 9s - loss: 0.0082 - acc: 0.9979\n",
      "Epoch 144/190\n",
      " - 9s - loss: 0.0051 - acc: 0.9984\n",
      "Epoch 145/190\n",
      " - 8s - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 146/190\n",
      " - 9s - loss: 0.0010 - acc: 0.9998\n",
      "Epoch 147/190\n",
      " - 8s - loss: 3.6796e-04 - acc: 1.0000\n",
      "Epoch 148/190\n",
      " - 8s - loss: 4.8867e-04 - acc: 1.0000\n",
      "Epoch 149/190\n",
      " - 9s - loss: 1.6459e-04 - acc: 1.0000\n",
      "Epoch 150/190\n",
      " - 9s - loss: 2.7611e-04 - acc: 1.0000\n",
      "Epoch 151/190\n",
      " - 8s - loss: 5.3129e-04 - acc: 0.9998\n",
      "Epoch 152/190\n",
      " - 9s - loss: 3.6009e-04 - acc: 1.0000\n",
      "Epoch 153/190\n",
      " - 9s - loss: 2.3858e-04 - acc: 1.0000\n",
      "Epoch 154/190\n",
      " - 8s - loss: 0.0010 - acc: 0.9994\n",
      "Epoch 155/190\n",
      " - 9s - loss: 0.0014 - acc: 0.9992\n",
      "Epoch 156/190\n",
      " - 9s - loss: 0.0097 - acc: 0.9965\n",
      "Epoch 157/190\n",
      " - 8s - loss: 0.0096 - acc: 0.9973\n",
      "Epoch 158/190\n",
      " - 9s - loss: 0.0108 - acc: 0.9953\n",
      "Epoch 159/190\n",
      " - 9s - loss: 0.0135 - acc: 0.9957\n",
      "Epoch 160/190\n",
      " - 8s - loss: 0.0103 - acc: 0.9963\n",
      "Epoch 161/190\n",
      " - 9s - loss: 0.0088 - acc: 0.9968\n",
      "Epoch 162/190\n",
      " - 9s - loss: 0.0053 - acc: 0.9982\n",
      "Epoch 163/190\n",
      " - 8s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 164/190\n",
      " - 9s - loss: 0.0048 - acc: 0.9984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/190\n",
      " - 8s - loss: 0.0056 - acc: 0.9980\n",
      "Epoch 166/190\n",
      " - 8s - loss: 0.0030 - acc: 0.9988\n",
      "Epoch 167/190\n",
      " - 9s - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 168/190\n",
      " - 8s - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 169/190\n",
      " - 8s - loss: 0.0229 - acc: 0.9947\n",
      "Epoch 170/190\n",
      " - 9s - loss: 0.0149 - acc: 0.9953\n",
      "Epoch 171/190\n",
      " - 9s - loss: 0.0028 - acc: 0.9990\n",
      "Epoch 172/190\n",
      " - 9s - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 173/190\n",
      " - 9s - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 174/190\n",
      " - 9s - loss: 0.0034 - acc: 0.9987\n",
      "Epoch 175/190\n",
      " - 9s - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 176/190\n",
      " - 9s - loss: 0.0019 - acc: 0.9988\n",
      "Epoch 177/190\n",
      " - 9s - loss: 0.0372 - acc: 0.9928\n",
      "Epoch 178/190\n",
      " - 8s - loss: 0.0195 - acc: 0.9959\n",
      "Epoch 179/190\n",
      " - 9s - loss: 0.0056 - acc: 0.9984\n",
      "Epoch 180/190\n",
      " - 9s - loss: 0.0025 - acc: 0.9990\n",
      "Epoch 181/190\n",
      " - 9s - loss: 0.0016 - acc: 0.9994\n",
      "Epoch 182/190\n",
      " - 9s - loss: 0.0014 - acc: 0.9994\n",
      "Epoch 183/190\n",
      " - 9s - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 184/190\n",
      " - 8s - loss: 0.0046 - acc: 0.9990\n",
      "Epoch 185/190\n",
      " - 9s - loss: 2.4314e-04 - acc: 1.0000\n",
      "Epoch 186/190\n",
      " - 9s - loss: 4.3219e-04 - acc: 0.9998\n",
      "Epoch 187/190\n",
      " - 8s - loss: 2.7918e-04 - acc: 1.0000\n",
      "Epoch 188/190\n",
      " - 9s - loss: 4.3156e-04 - acc: 0.9998\n",
      "Epoch 189/190\n",
      " - 9s - loss: 1.1085e-04 - acc: 1.0000\n",
      "Epoch 190/190\n",
      " - 8s - loss: 2.6121e-04 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "loss_metric = \"categorical_crossentropy\"\n",
    "model.compile(loss=loss_metric, metrics=[\"accuracy\"], \n",
    "              optimizer=optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=WEIGHT_DECAY, amsgrad=False))\n",
    "\n",
    "routine_dir = model_dir + \"routine-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "save_models = ModelCheckpoint(routine_dir, monitor='acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=10)\n",
    "best_dir = model_dir + \"best-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "save_best = ModelCheckpoint(best_dir, monitor='acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "#histories = Histories()\n",
    "res = model.fit_generator(train_generator, steps_per_epoch = math.ceil(5075/BATCH_SIZE), epochs=190, verbose=2, callbacks=[save_models, save_best])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Train Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1049061363234677146\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 79508275\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 10124132242725038463\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
